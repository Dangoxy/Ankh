from difflib import SequenceMatcher
import itertools
import ast
from PyQt5 import QtCore
from dictionaryMaker import dictionaryMaker
import ast


#Calls the makeDictionary on start.

dictionaryMaker.makeDictionary()

gardinersCodetoSymbolsf = {'A1':'ð“€€',
'A2':'ð“€',
'A3':'ð“€‚',
'A4':'ð“€ƒ',
'A5':'ð“€„',
'A5A':'ð“€…',
'A6':'ð“€†',
'A6A':'ð“€‡',
'A6B':'ð“€ˆ',
'A7':'ð“€‰',
'A8':'ð“€Š',
'A9':'ð“€‹',
'A10':'ð“€Œ',
'A11':'ð“€',
'A12':'ð“€Ž',
'A13':'ð“€',
'A14':'ð“€',
'A14A':'ð“€‘',
'A15':'ð“€’',
'A16':'ð“€“',
'A17':'ð“€”',
'A17A':'ð“€•',
'A18':'ð“€–',
'A19':'ð“€—',
'A20':'ð“€˜',
'A21':'ð“€™',
'A22':'ð“€š',
'A23':'ð“€›',
'A24':'ð“€œ',
'A25':'ð“€',
'A26':'ð“€ž',
'A27':'ð“€Ÿ',
'A28':'ð“€ ',
'A29':'ð“€¡',
'A30':'ð“€¢',
'A31':'ð“€£',
'A32':'ð“€¤',
'A32A':'ð“€¥',
'A33':'ð“€¦',
'A34':'ð“€§',
'A35':'ð“€¨',
'A36':'ð“€©',
'A37':'ð“€ª',
'A38':'ð“€«',
'A39':'ð“€¬',
'A40':'ð“€­',
'A40A':'ð“€®',
'A41':'ð“€¯',
'A42':'ð“€°',
'A42A':'ð“€±',
'A43':'ð“€²',
'A43A':'ð“€³',
'A44':'ð“€´',
'A45':'ð“€µ',
'A45A':'ð“€¶',
'A46':'ð“€·',
'A47':'ð“€¸',
'A48':'ð“€¹',
'A49':'ð“€º',
'A50':'ð“€»',
'A51':'ð“€¼',
'A52':'ð“€½',
'A53':'ð“€¾',
'A54':'ð“€¿',
'A55':'ð“€',
'A56':'ð“',
'A57':'ð“‚',
'A58':'ð“ƒ',
'A59':'ð“„',
'A60':'ð“…',
'A61':'ð“†',
'A62':'ð“‡',
'A63':'ð“ˆ',
'A64':'ð“‰',
'A65':'ð“Š',
'A66':'ð“‹',
'A67':'ð“Œ',
'A68':'ð“',
'A69':'ð“Ž',
'A70':'ð“',
'B1':'ð“',
'B2':'ð“‘',
'B3':'ð“’',
'B4':'ð““',
'B5':'ð“”',
'B5A':'ð“•',
'B6':'ð“–',
'B7':'ð“—',
'B8':'ð“˜',
'B9':'ð“™',
'C1':'ð“š',
'C2':'ð“›',
'C2A':'ð“œ',
'C2B':'ð“',
'C2C':'ð“ž',
'C3':'ð“Ÿ',
'C4':'ð“ ',
'C5':'ð“¡',
'C6':'ð“¢',
'C7':'ð“£',
'C8':'ð“¤',
'C9':'ð“¥',
'C10':'ð“¦',
'C10A':'ð“§',
'C11':'ð“¨',
'C12':'ð“©',
'C13':'ð“ª',
'C14':'ð“«',
'C15':'ð“¬',
'C16':'ð“­',
'C17':'ð“®',
'C18':'ð“¯',
'C19':'ð“°',
'C20':'ð“±',
'C21':'ð“²',
'C22':'ð“³',
'C23':'ð“´',
'C24':'ð“µ',
'D1':'ð“¶',
'D2':'ð“·',
'D3':'ð“¸',
'D4':'ð“¹',
'D5':'ð“º',
'D6':'ð“»',
'D7':'ð“¼',
'D8':'ð“½',
'D8A':'ð“¾',
'D9':'ð“¿',
'D10':'ð“‚€',
'D11':'ð“‚',
'D12':'ð“‚‚',
'D13':'ð“‚ƒ',
'D14':'ð“‚„',
'D15':'ð“‚…',
'D16':'ð“‚†',
'D17':'ð“‚‡',
'D18':'ð“‚ˆ',
'D19':'ð“‚‰',
'D20':'ð“‚Š',
'D21':'ð“‚‹',
'D22':'ð“‚Œ',
'D23':'ð“‚',
'D24':'ð“‚Ž',
'D25':'ð“‚',
'D26':'ð“‚',
'D27':'ð“‚‘',
'D27A':'ð“‚’',
'D28':'ð“‚“',
'D29':'ð“‚”',
'D30':'ð“‚•',
'D31':'ð“‚–',
'D31A':'ð“‚—',
'D32':'ð“‚˜',
'D33':'ð“‚™',
'D34':'ð“‚š',
'D34A':'ð“‚›',
'D35':'ð“‚œ',
'D36':'ð“‚',
'D37':'ð“‚ž',
'D38':'ð“‚Ÿ',
'D39':'ð“‚ ',
'D40':'ð“‚¡',
'D41':'ð“‚¢',
'D42':'ð“‚£',
'D43':'ð“‚¤',
'D44':'ð“‚¥',
'D45':'ð“‚¦',
'D46':'ð“‚§',
'D46A':'ð“‚¨',
'D47':'ð“‚©',
'D48':'ð“‚ª',
'D48A':'ð“‚«',
'D49':'ð“‚¬',
'D50':'ð“‚­',
'D50A':'ð“‚®',
'D50B':'ð“‚¯',
'D50C':'ð“‚°',
'D50D':'ð“‚±',
'D50E':'ð“‚²',
'D50F':'ð“‚³',
'D50G':'ð“‚´',
'D50H':'ð“‚µ',
'D50I':'ð“‚¶',
'D51':'ð“‚·',
'D52':'ð“‚¸',
'D52A':'ð“‚¹',
'D53':'ð“‚º',
'D54':'ð“‚»',
'D54A':'ð“‚¼',
'D55':'ð“‚½',
'D56':'ð“‚¾',
'D57':'ð“‚¿',
'D58':'ð“ƒ€',
'D59':'ð“ƒ',
'D60':'ð“ƒ‚',
'D61':'ð“ƒƒ',
'D62':'ð“ƒ„',
'D63':'ð“ƒ…',
'D64':'ð“ƒ†',
'D65':'ð“ƒ‡',
'D66':'ð“ƒˆ',
'D67':'ð“ƒ‰',
'D67A':'ð“ƒŠ',
'D67B':'ð“ƒ‹',
'D67C':'ð“ƒŒ',
'D67D':'ð“ƒ',
'D67E':'ð“ƒŽ',
'D67F':'ð“ƒ',
'D67G':'ð“ƒ',
'D67H':'ð“ƒ‘',
'E1':'ð“ƒ’',
'E2':'ð“ƒ“',
'E3':'ð“ƒ”',
'E4':'ð“ƒ•',
'E5':'ð“ƒ–',
'E6':'ð“ƒ—',
'E7':'ð“ƒ˜',
'E8':'ð“ƒ™',
'E8A':'ð“ƒš',
'E9':'ð“ƒ›',
'E9A':'ð“ƒœ',
'E10':'ð“ƒ',
'E11':'ð“ƒž',
'E12':'ð“ƒŸ',
'E13':'ð“ƒ ',
'E14':'ð“ƒ¡',
'E15':'ð“ƒ¢',
'E16':'ð“ƒ£',
'E16A':'ð“ƒ¤',
'E17':'ð“ƒ¥',
'E17A':'ð“ƒ¦',
'E18':'ð“ƒ§',
'E19':'ð“ƒ¨',
'E20':'ð“ƒ©',
'E20A':'ð“ƒª',
'E21':'ð“ƒ«',
'E22':'ð“ƒ¬',
'E23':'ð“ƒ­',
'E24':'ð“ƒ®',
'E25':'ð“ƒ¯',
'E26':'ð“ƒ°',
'E27':'ð“ƒ±',
'E28':'ð“ƒ²',
'E28A':'ð“ƒ³',
'E29':'ð“ƒ´',
'E30':'ð“ƒµ',
'E31':'ð“ƒ¶',
'E32':'ð“ƒ·',
'E33':'ð“ƒ¸',
'E34':'ð“ƒ¹',
'E34A':'ð“ƒº',
'E36':'ð“ƒ»',
'E37':'ð“ƒ¼',
'E38':'ð“ƒ½',
'F1':'ð“ƒ¾',
'F1A':'ð“ƒ¿',
'F2':'ð“„€',
'F3':'ð“„',
'F4':'ð“„‚',
'F5':'ð“„ƒ',
'F6':'ð“„„',
'F7':'ð“„…',
'F8':'ð“„†',
'F9':'ð“„‡',
'F10':'ð“„ˆ',
'F11':'ð“„‰',
'F12':'ð“„Š',
'F13':'ð“„‹',
'F13A':'ð“„Œ',
'F14':'ð“„',
'F15':'ð“„Ž',
'F16':'ð“„',
'F17':'ð“„',
'F18':'ð“„‘',
'F19':'ð“„’',
'F20':'ð“„“',
'F21':'ð“„”',
'F21A':'ð“„•',
'F22':'ð“„–',
'F23':'ð“„—',
'F24':'ð“„˜',
'F25':'ð“„™',
'F26':'ð“„š',
'F27':'ð“„›',
'F28':'ð“„œ',
'F29':'ð“„',
'F30':'ð“„ž',
'F31':'ð“„Ÿ',
'F31A':'ð“„ ',
'F32':'ð“„¡',
'F33':'ð“„¢',
'F34':'ð“„£',
'F35':'ð“„¤',
'F36':'ð“„¥',
'F37':'ð“„¦',
'F37A':'ð“„§',
'F38':'ð“„¨',
'F38A':'ð“„©',
'F39':'ð“„ª',
'F40':'ð“„«',
'F41':'ð“„¬',
'F42':'ð“„­',
'F43':'ð“„®',
'F44':'ð“„¯',
'F45':'ð“„°',
'F45A':'ð“„±',
'F46':'ð“„²',
'F46A':'ð“„³',
'F47':'ð“„´',
'F47A':'ð“„µ',
'F48':'ð“„¶',
'F49':'ð“„·',
'F50':'ð“„¸',
'F51':'ð“„¹',
'F51A':'ð“„º',
'F51B':'ð“„»',
'F51C':'ð“„¼',
'F52':'ð“„½',
'F53':'ð“„¾',
'G1':'ð“„¿',
'G2':'ð“…€',
'G3':'ð“…',
'G4':'ð“…‚',
'G5':'ð“…ƒ',
'G6':'ð“…„',
'G6A':'ð“……',
'G7':'ð“…†',
'G7A':'ð“…‡',
'G7B':'ð“…ˆ',
'G8':'ð“…‰',
'G9':'ð“…Š',
'G10':'ð“…‹',
'G11':'ð“…Œ',
'G11A':'ð“…',
'G12':'ð“…Ž',
'G13':'ð“…',
'G14':'ð“…',
'G15':'ð“…‘',
'G16':'ð“…’',
'G17':'ð“…“',
'G18':'ð“…”',
'G19':'ð“…•',
'G20':'ð“…–',
'G20A':'ð“…—',
'G21':'ð“…˜',
'G22':'ð“…™',
'G23':'ð“…š',
'G24':'ð“…›',
'G25':'ð“…œ',
'G26':'ð“…',
'G26A':'ð“…ž',
'G27':'ð“…Ÿ',
'G28':'ð“… ',
'G29':'ð“…¡',
'G30':'ð“…¢',
'G31':'ð“…£',
'G32':'ð“…¤',
'G33':'ð“…¥',
'G34':'ð“…¦',
'G35':'ð“…§',
'G36':'ð“…¨',
'G36A':'ð“…©',
'G37':'ð“…ª',
'G37A':'ð“…«',
'G38':'ð“…¬',
'G39':'ð“…­',
'G40':'ð“…®',
'G41':'ð“…¯',
'G42':'ð“…°',
'G43':'ð“…±',
'G43A':'ð“…²',
'G44':'ð“…³',
'G45':'ð“…´',
'G45A':'ð“…µ',
'G46':'ð“…¶',
'G47':'ð“…·',
'G48':'ð“…¸',
'G49':'ð“…¹',
'G50':'ð“…º',
'G51':'ð“…»',
'G52':'ð“…¼',
'G53':'ð“…½',
'G54':'ð“…¾',
'H1':'ð“…¿',
'H2':'ð“†€',
'H3':'ð“†',
'H4':'ð“†‚',
'H5':'ð“†ƒ',
'H6':'ð“†„',
'H6A':'ð“†…',
'H7':'ð“††',
'H8':'ð“†‡',
'I1':'ð“†ˆ',
'I2':'ð“†‰',
'I3':'ð“†Š',
'I4':'ð“†‹',
'I5':'ð“†Œ',
'I5A':'ð“†',
'I6':'ð“†Ž',
'I7':'ð“†',
'I8':'ð“†',
'I9':'ð“†‘',
'I9A':'ð“†’',
'I10':'ð“†“',
'I10A':'ð“†”',
'I11':'ð“†•',
'I11A':'ð“†–',
'I12':'ð“†—',
'I13':'ð“†˜',
'I14':'ð“†™',
'I15':'ð“†š',
'K1':'ð“†›',
'K2':'ð“†œ',
'K3':'ð“†',
'K4':'ð“†ž',
'K5':'ð“†Ÿ',
'K6':'ð“† ',
'K7':'ð“†¡',
'K8':'ð“†¢',
'L1':'ð“†£',
'L2':'ð“†¤',
'L2A':'ð“†¥',
'L3':'ð“†¦',
'L4':'ð“†§',
'L5':'ð“†¨',
'L6':'ð“†©',
'L6A':'ð“†ª',
'L7':'ð“†«',
'L8':'ð“†¬',
'M1':'ð“†­',
'M1A':'ð“†®',
'M1B':'ð“†¯',
'M2':'ð“†°',
'M3':'ð“†±',
'M3A':'ð“†²',
'M4':'ð“†³',
'M5':'ð“†´',
'M6':'ð“†µ',
'M7':'ð“†¶',
'M8':'ð“†·',
'M9':'ð“†¸',
'M10':'ð“†¹',
'M10A':'ð“†º',
'M11':'ð“†»',
'M12':'ð“†¼',
'M12A':'ð“†½',
'M12B':'ð“†¾',
'M12C':'ð“†¿',
'M12D':'ð“‡€',
'M12E':'ð“‡',
'M12F':'ð“‡‚',
'M12G':'ð“‡ƒ',
'M12H':'ð“‡„',
'M13':'ð“‡…',
'M14':'ð“‡†',
'M15':'ð“‡‡',
'M15A':'ð“‡ˆ',
'M16':'ð“‡‰',
'M16A':'ð“‡Š',
'M17':'ð“‡‹',
'M17A':'ð“‡Œ',
'M18':'ð“‡',
'M19':'ð“‡Ž',
'M20':'ð“‡',
'M21':'ð“‡',
'M22':'ð“‡‘',
'M22A':'ð“‡’',
'M23':'ð“‡“',
'M24':'ð“‡”',
'M24A':'ð“‡•',
'M25':'ð“‡–',
'M26':'ð“‡—',
'M27':'ð“‡˜',
'M28':'ð“‡™',
'M28A':'ð“‡š',
'M29':'ð“‡›',
'M30':'ð“‡œ',
'M31':'ð“‡',
'M31A':'ð“‡ž',
'M32':'ð“‡Ÿ',
'M33':'ð“‡ ',
'M33A':'ð“‡¡',
'M33B':'ð“‡¢',
'M34':'ð“‡£',
'M35':'ð“‡¤',
'M36':'ð“‡¥',
'M37':'ð“‡¦',
'M38':'ð“‡§',
'M39':'ð“‡¨',
'M40':'ð“‡©',
'M40A':'ð“‡ª',
'M41':'ð“‡«',
'M42':'ð“‡¬',
'M43':'ð“‡­',
'M44':'ð“‡®',
'N1':'ð“‡¯',
'N2':'ð“‡°',
'N3':'ð“‡±',
'N4':'ð“‡²',
'N5':'ð“‡³',
'N6':'ð“‡´',
'N7':'ð“‡µ',
'N8':'ð“‡¶',
'N9':'ð“‡·',
'N10':'ð“‡¸',
'N11':'ð“‡¹',
'N12':'ð“‡º',
'N13':'ð“‡»',
'N14':'ð“‡¼',
'N15':'ð“‡½',
'N16':'ð“‡¾',
'N17':'ð“‡¿',
'N18':'ð“ˆ€',
'N18A':'ð“ˆ',
'N18B':'ð“ˆ‚',
'N19':'ð“ˆƒ',
'N20':'ð“ˆ„',
'N21':'ð“ˆ…',
'N22':'ð“ˆ†',
'N23':'ð“ˆ‡',
'N24':'ð“ˆˆ',
'N25':'ð“ˆ‰',
'N25A':'ð“ˆŠ',
'N26':'ð“ˆ‹',
'N27':'ð“ˆŒ',
'N28':'ð“ˆ',
'N29':'ð“ˆŽ',
'N30':'ð“ˆ',
'N31':'ð“ˆ',
'N32':'ð“ˆ‘',
'N33':'ð“ˆ’',
'N33A':'ð“ˆ“',
'N34':'ð“ˆ”',
'N34A':'ð“ˆ•',
'N35':'ð“ˆ–',
'N35A':'ð“ˆ—',
'N36':'ð“ˆ˜',
'N37':'ð“ˆ™',
'N37A':'ð“ˆš',
'N38':'ð“ˆ›',
'N39':'ð“ˆœ',
'N40':'ð“ˆ',
'N41':'ð“ˆž',
'N42':'ð“ˆŸ',
'NL1':'ð“ˆ ',
'NL2':'ð“ˆ¡',
'NL3':'ð“ˆ¢',
'NL4':'ð“ˆ£',
'NL5':'ð“ˆ¤',
'NL5a':'ð“ˆ¥',
'NL6':'ð“ˆ¦',
'NL7':'ð“ˆ§',
'NL8':'ð“ˆ¨',
'NL9':'ð“ˆ©',
'NL10':'ð“ˆª',
'NL11':'ð“ˆ«',
'NL12':'ð“ˆ¬',
'NL13':'ð“ˆ­',
'NL14':'ð“ˆ®',
'NL15':'ð“ˆ¯',
'NL16':'ð“ˆ°',
'NL17':'ð“ˆ±',
'NL17a':'ð“ˆ²',
'NL18':'ð“ˆ³',
'NL19':'ð“ˆ´',
'NL20':'ð“ˆµ',
'NU1':'ð“ˆ¶',
'NU2':'ð“ˆ·',
'NU3':'ð“ˆ¸',
'NU4':'ð“ˆ¹',
'NU5':'ð“ˆº',
'NU6':'ð“ˆ»',
'NU7':'ð“ˆ¼',
'NU8':'ð“ˆ½',
'NU9':'ð“ˆ¾',
'NU10':'ð“ˆ¿',
'NU10a':'ð“‰€',
'NU11':'ð“‰',
'NU11a':'ð“‰‚',
'NU12':'ð“‰ƒ',
'NU13':'ð“‰„',
'NU14':'ð“‰…',
'NU15':'ð“‰†',
'NU16':'ð“‰‡',
'NU17':'ð“‰ˆ',
'NU18':'ð“‰‰',
'NU18a':'ð“‰Š',
'NU19':'ð“‰‹',
'NU20':'ð“‰Œ',
'NU21':'ð“‰',
'NU22':'ð“‰Ž',
'NU22a':'ð“‰',
'O1':'ð“‰',
'O1A':'ð“‰‘',
'O2':'ð“‰’',
'O3':'ð“‰“',
'O4':'ð“‰”',
'O5':'ð“‰•',
'O5A':'ð“‰–',
'O6':'ð“‰—',
'O6A':'ð“‰˜',
'O6B':'ð“‰™',
'O6C':'ð“‰š',
'O6D':'ð“‰›',
'O6E':'ð“‰œ',
'O6F':'ð“‰',
'O7':'ð“‰ž',
'O8':'ð“‰Ÿ',
'O9':'ð“‰ ',
'O10':'ð“‰¡',
'O10A':'ð“‰¢',
'O10B':'ð“‰£',
'O10C':'ð“‰¤',
'O11':'ð“‰¥',
'O12':'ð“‰¦',
'O13':'ð“‰§',
'O14':'ð“‰¨',
'O15':'ð“‰©',
'O16':'ð“‰ª',
'O17':'ð“‰«',
'O18':'ð“‰¬',
'O19':'ð“‰­',
'O19A':'ð“‰®',
'O20':'ð“‰¯',
'O20A':'ð“‰°',
'O21':'ð“‰±',
'O22':'ð“‰²',
'O23':'ð“‰³',
'O24':'ð“‰´',
'O24A':'ð“‰µ',
'O25':'ð“‰¶',
'O25A':'ð“‰·',
'O26':'ð“‰¸',
'O27':'ð“‰¹',
'O28':'ð“‰º',
'O29':'ð“‰»',
'O29A':'ð“‰¼',
'O30':'ð“‰½',
'O30A':'ð“‰¾',
'O31':'ð“‰¿',
'O32':'ð“Š€',
'O33':'ð“Š',
'O33A':'ð“Š‚',
'O34':'ð“Šƒ',
'O35':'ð“Š„',
'O36':'ð“Š…',
'O36A':'ð“Š†',
'O36B':'ð“Š‡',
'O36C':'ð“Šˆ',
'O36D':'ð“Š‰',
'O37':'ð“ŠŠ',
'O38':'ð“Š‹',
'O39':'ð“ŠŒ',
'O40':'ð“Š',
'O41':'ð“ŠŽ',
'O42':'ð“Š',
'O43':'ð“Š',
'O44':'ð“Š‘',
'O45':'ð“Š’',
'O46':'ð“Š“',
'O47':'ð“Š”',
'O48':'ð“Š•',
'O49':'ð“Š–',
'O50':'ð“Š—',
'O50A':'ð“Š˜',
'O50B':'ð“Š™',
'O51':'ð“Šš',
'P1':'ð“Š›',
'P1A':'ð“Šœ',
'P2':'ð“Š',
'P3':'ð“Šž',
'P3A':'ð“ŠŸ',
'P4':'ð“Š ',
'P5':'ð“Š¡',
'P6':'ð“Š¢',
'P7':'ð“Š£',
'P8':'ð“Š¤',
'P9':'ð“Š¥',
'P10':'ð“Š¦',
'P11':'ð“Š§',
'Q1':'ð“Š¨',
'Q2':'ð“Š©',
'Q3':'ð“Šª',
'Q4':'ð“Š«',
'Q5':'ð“Š¬',
'Q6':'ð“Š­',
'Q7':'ð“Š®',
'R1':'ð“Š¯',
'R2':'ð“Š°',
'R2A':'ð“Š±',
'R3':'ð“Š²',
'R3A':'ð“Š³',
'R3B':'ð“Š´',
'R4':'ð“Šµ',
'R5':'ð“Š¶',
'R6':'ð“Š·',
'R7':'ð“Š¸',
'R8':'ð“Š¹',
'R9':'ð“Šº',
'R10':'ð“Š»',
'R10A':'ð“Š¼',
'R11':'ð“Š½',
'R12':'ð“Š¾',
'R13':'ð“Š¿',
'R14':'ð“‹€',
'R15':'ð“‹',
'R16':'ð“‹‚',
'R16A':'ð“‹ƒ',
'R17':'ð“‹„',
'R18':'ð“‹…',
'R19':'ð“‹†',
'R20':'ð“‹‡',
'R21':'ð“‹ˆ',
'R22':'ð“‹‰',
'R23':'ð“‹Š',
'R24':'ð“‹‹',
'R25':'ð“‹Œ',
'R26':'ð“‹',
'R27':'ð“‹Ž',
'R28':'ð“‹',
'R29':'ð“‹',
'S1':'ð“‹‘',
'S2':'ð“‹’',
'S2A':'ð“‹“',
'S3':'ð“‹”',
'S4':'ð“‹•',
'S5':'ð“‹–',
'S6':'ð“‹—',
'S6A':'ð“‹˜',
'S7':'ð“‹™',
'S8':'ð“‹š',
'S9':'ð“‹›',
'S10':'ð“‹œ',
'S11':'ð“‹',
'S12':'ð“‹ž',
'S13':'ð“‹Ÿ',
'S14':'ð“‹ ',
'S14A':'ð“‹¡',
'S14B':'ð“‹¢',
'S15':'ð“‹£',
'S16':'ð“‹¤',
'S17':'ð“‹¥',
'S17A':'ð“‹¦',
'S18':'ð“‹§',
'S19':'ð“‹¨',
'S20':'ð“‹©',
'S21':'ð“‹ª',
'S22':'ð“‹«',
'S23':'ð“‹¬',
'S24':'ð“‹­',
'S25':'ð“‹®',
'S26':'ð“‹¯',
'S26A':'ð“‹°',
'S26B':'ð“‹±',
'S27':'ð“‹²',
'S28':'ð“‹³',
'S29':'ð“‹´',
'S30':'ð“‹µ',
'S31':'ð“‹¶',
'S32':'ð“‹·',
'S33':'ð“‹¸',
'S34':'ð“‹¹',
'S35':'ð“‹º',
'S35A':'ð“‹»',
'S36':'ð“‹¼',
'S37':'ð“‹½',
'S38':'ð“‹¾',
'S39':'ð“‹¿',
'S40':'ð“Œ€',
'S41':'ð“Œ',
'S42':'ð“Œ‚',
'S43':'ð“Œƒ',
'S44':'ð“Œ„',
'S45':'ð“Œ…',
'S46':'ð“Œ†',
'T1':'ð“Œ‡',
'T2':'ð“Œˆ',
'T3':'ð“Œ‰',
'T3A':'ð“ŒŠ',
'T4':'ð“Œ‹',
'T5':'ð“ŒŒ',
'T6':'ð“Œ',
'T7':'ð“ŒŽ',
'T7A':'ð“Œ',
'T8':'ð“Œ',
'T8A':'ð“Œ‘',
'T9':'ð“Œ’',
'T9A':'ð“Œ“',
'T10':'ð“Œ”',
'T11':'ð“Œ•',
'T11A':'ð“Œ–',
'T12':'ð“Œ—',
'T13':'ð“Œ˜',
'T14':'ð“Œ™',
'T15':'ð“Œš',
'T16':'ð“Œ›',
'T16A':'ð“Œœ',
'T17':'ð“Œ',
'T18':'ð“Œž',
'T19':'ð“ŒŸ',
'T20':'ð“Œ ',
'T21':'ð“Œ¡',
'T22':'ð“Œ¢',
'T23':'ð“Œ£',
'T24':'ð“Œ¤',
'T25':'ð“Œ¥',
'T26':'ð“Œ¦',
'T27':'ð“Œ§',
'T28':'ð“Œ¨',
'T29':'ð“Œ©',
'T30':'ð“Œª',
'T31':'ð“Œ«',
'T32':'ð“Œ¬',
'T32A':'ð“Œ­',
'T33':'ð“Œ®',
'T33A':'ð“Œ¯',
'T34':'ð“Œ°',
'T35':'ð“Œ±',
'T36':'ð“Œ²',
'U1':'ð“Œ³',
'U2':'ð“Œ´',
'U3':'ð“Œµ',
'U4':'ð“Œ¶',
'U5':'ð“Œ·',
'U6':'ð“Œ¸',
'U6A':'ð“Œ¹',
'U6B':'ð“Œº',
'U7':'ð“Œ»',
'U8':'ð“Œ¼',
'U9':'ð“Œ½',
'U10':'ð“Œ¾',
'U11':'ð“Œ¿',
'U12':'ð“€',
'U13':'ð“',
'U14':'ð“‚',
'U15':'ð“ƒ',
'U16':'ð“„',
'U17':'ð“…',
'U18':'ð“†',
'U19':'ð“‡',
'U20':'ð“ˆ',
'U21':'ð“‰',
'U22':'ð“Š',
'U23':'ð“‹',
'U23A':'ð“Œ',
'U24':'ð“',
'U25':'ð“Ž',
'U26':'ð“',
'U27':'ð“',
'U28':'ð“‘',
'U29':'ð“’',
'U29A':'ð““',
'U30':'ð“”',
'U31':'ð“•',
'U32':'ð“–',
'U32A':'ð“—',
'U33':'ð“˜',
'U34':'ð“™',
'U35':'ð“š',
'U36':'ð“›',
'U37':'ð“œ',
'U38':'ð“',
'U39':'ð“ž',
'U40':'ð“Ÿ',
'U41':'ð“ ',
'U42':'ð“¡',
'V1':'ð“¢',
'V1A':'ð“£',
'V1B':'ð“¤',
'V1C':'ð“¥',
'V1D':'ð“¦',
'V1E':'ð“§',
'V1F':'ð“¨',
'V1G':'ð“©',
'V1H':'ð“ª',
'V1I':'ð“«',
'V2':'ð“¬',
'V2A':'ð“­',
'V3':'ð“®',
'V4':'ð“¯',
'V5':'ð“°',
'V6':'ð“±',
'V7':'ð“²',
'V7A':'ð“³',
'V7B':'ð“´',
'V8':'ð“µ',
'V9':'ð“¶',
'V10':'ð“·',
'V11':'ð“¸',
'V11A':'ð“¹',
'V11B':'ð“º',
'V11C':'ð“»',
'V12':'ð“¼',
'V12A':'ð“½',
'V12B':'ð“¾',
'V13':'ð“¿',
'V14':'ð“Ž€',
'V15':'ð“Ž',
'V16':'ð“Ž‚',
'V17':'ð“Žƒ',
'V18':'ð“Ž„',
'V19':'ð“Ž…',
'V20':'ð“Ž†',
'V20A':'ð“Ž‡',
'V20B':'ð“Žˆ',
'V20C':'ð“Ž‰',
'V20D':'ð“ŽŠ',
'V20E':'ð“Ž‹',
'V20F':'ð“ŽŒ',
'V20G':'ð“Ž',
'V20H':'ð“ŽŽ',
'V20I':'ð“Ž',
'V20J':'ð“Ž',
'V20K':'ð“Ž‘',
'V20L':'ð“Ž’',
'V21':'ð“Ž“',
'V22':'ð“Ž”',
'V23':'ð“Ž•',
'V23A':'ð“Ž–',
'V24':'ð“Ž—',
'V25':'ð“Ž˜',
'V26':'ð“Ž™',
'V27':'ð“Žš',
'V28':'ð“Ž›',
'V28A':'ð“Žœ',
'V29':'ð“Ž',
'V29A':'ð“Žž',
'V30':'ð“ŽŸ',
'V30A':'ð“Ž ',
'V31':'ð“Ž¡',
'V31A':'ð“Ž¢',
'V32':'ð“Ž£',
'V33':'ð“Ž¤',
'V33A':'ð“Ž¥',
'V34':'ð“Ž¦',
'V35':'ð“Ž§',
'V36':'ð“Ž¨',
'V37':'ð“Ž©',
'V37A':'ð“Žª',
'V38':'ð“Ž«',
'V39':'ð“Ž¬',
'V40':'ð“Ž­',
'V40A':'ð“Ž®',
'W1':'ð“Ž¯',
'W2':'ð“Ž°',
'W3':'ð“Ž±',
'W3A':'ð“Ž²',
'W4':'ð“Ž³',
'W5':'ð“Ž´',
'W6':'ð“Žµ',
'W7':'ð“Ž¶',
'W8':'ð“Ž·',
'W9':'ð“Ž¸',
'W9A':'ð“Ž¹',
'W10':'ð“Žº',
'W10A':'ð“Ž»',
'W11':'ð“Ž¼',
'W12':'ð“Ž½',
'W13':'ð“Ž¾',
'W14':'ð“Ž¿',
'W14A':'ð“€',
'W15':'ð“',
'W16':'ð“‚',
'W17':'ð“ƒ',
'W17A':'ð“„',
'W18':'ð“…',
'W18A':'ð“†',
'W19':'ð“‡',
'W20':'ð“ˆ',
'W21':'ð“‰',
'W22':'ð“Š',
'W23':'ð“‹',
'W24':'ð“Œ',
'W24A':'ð“',
'W25':'ð“Ž',
'X1':'ð“',
'X2':'ð“',
'X3':'ð“‘',
'X4':'ð“’',
'X4A':'ð““',
'X4B':'ð“”',
'X5':'ð“•',
'X6':'ð“–',
'X6A':'ð“—',
'X7':'ð“˜',
'X8':'ð“™',
'X8A':'ð“š',
'Y1':'ð“›',
'Y1A':'ð“œ',
'Y2':'ð“',
'Y3':'ð“ž',
'Y4':'ð“Ÿ',
'Y5':'ð“ ',
'Y6':'ð“¡',
'Y7':'ð“¢',
'Y8':'ð“£',
'Z1':'ð“¤',
'Z2':'ð“¥',
'Z2A':'ð“¦',
'Z2B':'ð“§',
'Z2C':'ð“¨',
'Z2D':'ð“©',
'Z3':'ð“ª',
'Z3A':'ð“«',
'Z3B':'ð“¬',
'Z4':'ð“­',
'Z4A':'ð“®',
'Z5':'ð“¯',
'Z5A':'ð“°',
'Z6':'ð“±',
'Z7':'ð“²',
'Z8':'ð“³',
'Z9':'ð“´',
'Z10':'ð“µ',
'Z11':'ð“¶',
'Z12':'ð“·',
'Z13':'ð“¸',
'Z14':'ð“¹',
'Z15':'ð“º',
'Z15A':'ð“»',
'Z15B':'ð“¼',
'Z15C':'ð“½',
'Z15D':'ð“¾',
'Z15E':'ð“¿',
'Z15F':'ð“€',
'Z15G':'ð“',
'Z15H':'ð“‚',
'Z15I':'ð“ƒ',
'Z16':'ð“„',
'Z16A':'ð“…',
'Z16B':'ð“†',
'Z16C':'ð“‡',
'Z16D':'ð“ˆ',
'Z16E':'ð“‰',
'Z16F':'ð“Š',
'Z16G':'ð“‹',
'Z16H':'ð“Œ',
'Aa1':'ð“',
'Aa2':'ð“Ž',
'Aa3':'ð“',
'Aa4':'ð“',
'Aa5':'ð“‘',
'Aa6':'ð“’',
'Aa7':'ð““',
'Aa7A':'ð“”',
'Aa7B':'ð“•',
'Aa8':'ð“–',
'Aa9':'ð“—',
'Aa10':'ð“˜',
'Aa11':'ð“™',
'Aa12':'ð“š',
'Aa13':'ð“›',
'Aa14':'ð“œ',
'Aa15':'ð“',
'Aa16':'ð“ž',
'Aa17':'ð“Ÿ',
'Aa18':'ð“ ',
'Aa19':'ð“¡',
'Aa20':'ð“¢',
'Aa21':'ð“£',
'Aa22':'ð“¤',
'Aa23':'ð“¥',
'Aa24':'ð“¦',
'Aa25':'ð“§',
'Aa26':'ð“¨',
'Aa27':'ð“©',
'Aa28':'ð“ª',
'Aa29':'ð“«',
'Aa30':'ð“¬',
'Aa31':'ð“­',
'Aa32':'ð“®'}

def similar(a, b):

    #Using the SequenceMatcher function, return the similarity ratio.

    return SequenceMatcher(None, a, b).ratio()

def gardinersMultiDirect (incode):

    #This function just takes gardiners code, and turns it into symbols using the dictionary.
     
    founding = ""

    if "}" in incode:
        incode = incode.replace("}"," ")

    for word in incode.split("  "):
        for c in word.split(" "):
            
            for code, sym in gardinersCodetoSymbolsf.items():

                if c.lower() == code.lower():
                    founding += ( sym + " ")

            if c.lower() == "-":
                founding += ("-")


        founding += "  "

    return founding
  
def newSearchForEng(sen,dictionaryFull):

    #This function translates English to Hieroglyphs, Transliteration, and Gardiner's code, and it returns then and moreinfo variable.

    #Making some variables to store values in to return later.

    temp = []
    newWord = ""
    codeper = {}
    foundings = ""
    foundforgard = ""
    moreinfo = ""
    ogsen = []

    foundcheck = False

    for word in sen.lower().split(" "):
        ogsen.append(word)

    for word in sen.lower().split(" "):
        temp.append(word)
    
    while len(ogsen) != 0:
        
        foundcheck = False

        while len(temp) != 0:
            newWord = ""
            for i in range(len(temp)):
                if temp[i] != temp[-1]:
                    newWord += temp[i] + " "
                else: newWord += temp[i]


            for code, trans in dictionaryFull.items():

                #if list

                if isinstance(trans, list):

                    #loop to clean the word from its surrounding

                    for word in trans:

                    #if it matches we add it to a temp dictionary

                        if ")" in word and "(" in word:
                            b1 = word.index("(")
                            b2 = word.index(")")
                            sb = word.index("]")
                            if (b1-2) == sb:
                                word = word[b2+1:]
                            elif (b1-2) != sb:
                                word = word[sb+1:]
                        elif "]" in word:
                            sb = word.index("]")
                            word = word[sb+1:]

                        #if it matches we add it to a temp dictionary

                        if newWord == word.lower().strip() and len(word) != 0 and len(newWord) != 0:
                            per = (len(newWord)/len(word.lower().strip())*100) + 5
                            codeper[code] = per
                            foundcheck = True

                        elif newWord in word.lower().strip() and len(word) != 0 and len(newWord) != 0:
                            per = (len(newWord)/len(word.lower().strip())*100)
                            codeper[code] = per
                            foundcheck = True
                        else:
                            per = 0
                            codeper["{-}"] = per


                #else if not list

                elif isinstance(trans, str):

                    #cleans word

                    if ")" in trans:
                        b1 = trans.index("(")
                        b2 = trans.index(")")
                        sb = trans.index("]")
                        if (b1-2) == sb:
                            trans = trans[b2+1:]
                        elif (b1-2) != sb:
                            trans = trans[sb+1:]
                    elif "]" in trans:
                        sb = trans.index("]")
                        trans = trans[sb+1:]

                    #if it matches we add it to a temp dictionary

                    if newWord == trans.lower().strip() and len(trans) != 0 and len(newWord) != 0:
                        per = (len(newWord)/len(trans.lower().strip())*100) + 10
                        codeper[code] = per
                        foundcheck = True

                    elif newWord in trans.lower().strip() and len(trans) != 0 and len(newWord) != 0:
                        per = (len(newWord)/len(trans.lower().strip())*100) + 5
                        codeper[code] = per
                        foundcheck = True
                    else:
                        per = 0
                        codeper["{-}"] = per
                
            if foundcheck:
                for i in newWord.split(" "):
                    temp.remove(i)
                    ogsen.remove(i)
            else:
                temp.pop()
                        

            #if the temp dictionary isnt empty, it finds the max of the dictionary (the one with the best accuracy)
            # and returns it and adds it formatted to get translated into symbols using the Gardiner function.

            

        if len(codeper) != 0:
            maxv = max(codeper, key=codeper.get)
            if maxv != "{-}":

                result = maxv + " " +  str(codeper[maxv]) + "% (" + newWord + ")"
                print(result)
                moreinfo += ("More info: (" + str(codeper[maxv]) + "%) " + str(maxv) + ": " + str(dictionaryFull[maxv]) +"\n")
                foundings += (result + " ")
                foundforgard += (str(maxv) + " ")
                codeper.clear()

            else:

                result = maxv + " Not found" + "% (" + newWord + ")"
                print(result)
                moreinfo += ("More info: " ": Not found" +"\n")
                foundings += (result + " ")
                foundforgard += (str(maxv) + " ")
                codeper.clear()

        if not foundcheck:
            ogsen.remove(ogsen[0])

        temp = ogsen.copy()    
        #returns the stats for found words.



    transl = ""
    for i in foundforgard.split("} "):
        n = i+ "}"
        
        if n != "}":
            c = dictionaryFull.get(n,"notfound")

            if isinstance(c,list):
                for i in c:
                    if "notfound" not in i.lower():
                        if ")" and "(" in i.lower():
                            b = i.index("(")
                            e= i.index(")")
                            tr = i[b:e+1]
                            i = i.replace(tr,"")
                        if "notfound" not in i.lower():
                            tt = (i[i.index("["):i.index("]")+1])
                            transl += tt +" "
                            break
                        else: transl += "[-] "
                
            if isinstance(c, str):
                if ")" and "(" in c.lower():
                            b = c.index("(")
                            e= c.index(")")
                            tr = c[b:e+1]
                            c = c.replace(tr,"")
                if "notfound" not in c.lower():
                    tt = (c[c.index("["):c.index("]")+1])
                    transl += tt+ " "
                else: transl += "[-] "


    
    res = foundforgard.replace("{", "")
    hiero = gardinersMultiDirect(res)
    print("\n" + moreinfo)
    print(foundforgard)
    print(transl)
    print(hiero)
    return moreinfo,foundforgard,transl,hiero

    #calls function to translate to symbols using gardiners code.

def newSearchForTransl(sen,dictionaryFull):
    temp = []
    newWord = ""

    codeper = {}
    foundings = ""
    foundforgard = ""
    moreinfo = ""

    ogsen = []

    foundcheck = False

    for word in sen.split(" "):
        ogsen.append(word)

    for word in sen.split(" "):
        temp.append(word)
    
    while len(ogsen) != 0:
        
        foundcheck = False

        while len(temp) != 0:
            newWord = ""
            for i in range(len(temp)):
                if temp[i] != temp[-1]:
                    newWord += temp[i] + " "
                else: newWord += temp[i]

            #if found --------

            for code, trans in dictionaryFull.items():

                #if list

                if isinstance(trans, list):

                    #loop to clean the word from its surrounding

                    for word in trans:

                    #if it matches we add it to a temp dictionary

                        if "]" in word and "[" in word:
                            esb = word.index("]")
                            bsb = word.index("[")
                            word = word[bsb:esb+1]

                        #if it matches we add it to a temp dictionary

                        if newWord == word.strip():
                            #per = (len(newWord)/len(word.lower().strip())*100) + 5
                            newWordp = "[" +newWord +"]"
                            per = similar(newWordp,word.strip())*100 +5
                            #print("sure match (", per, ")", code)
                            codeper[code] = per
                            foundcheck = True

                        elif newWord in word.strip():
                            #per = (len(newWord)/len(word.lower().strip())*100)
                            newWordp = "[" +newWord +"]"
                            per = similar(newWordp,word.strip())*100
                            #print("not accurate (", per, ")", code)
                            codeper[code] = per
                            foundcheck = True
                            #or word.lower().strip() in newWord
                        else:
                            per = 0
                            codeper["-"] = per


                #else if not list

                elif isinstance(trans, str):

                    #cleans word

                    if "]" in trans and "[" in trans:
                        esb = trans.index("]")
                        bsb = trans.index("[")

                        trans = trans[bsb:esb+1]

                    #if it matches we add it to a temp dictionary

                    if newWord == trans.strip():
                        #per = (len(newWord)/len(trans.lower().strip())*100) + 10
                        newWordp = "[" +newWord +"]"
                        per = similar(newWordp,trans.strip())*100+10
                        #print("sure match (", per, ")", code)
                        codeper[code] = per
                        foundcheck = True

                    elif newWord in trans.strip():
                        #per = (len(newWord)/len(trans.lower().strip())*100) + 5
                        newWordp = "[" +newWord +"]"
                        per = similar(newWordp,trans.strip())*100 +5
                        #print("not accurate (", per, ")", code)
                        codeper[code] = per
                        foundcheck = True
                    else:
                        per = 0
                        codeper["{-}"] = per
                
            if foundcheck:
                for i in newWord.split(" "):
                    temp.remove(i)
                    ogsen.remove(i)
            else:
                temp.pop()
                        

            #if the temp dictionary isnt empty, it finds the max of the dictionary (the one with the best accuracy)
            # and returns it and adds it formatted to get translated into symbols using the Gardiner function.

            

        if len(codeper) != 0:
            #print(codeper)
            #print(len(codeper))
            maxv = max(codeper, key=codeper.get)
            if maxv != "-":

                result = maxv + " " +  str(codeper[maxv]) + "% (" + newWord + ")"
                    
                print(result)
                moreinfo += ("More info: (" + str(codeper[maxv]) + "%) " + str(maxv) + ": " + str(dictionaryFull[maxv]) +"\n")
                foundings += (result + " ")
                foundforgard += (str(maxv) + " ")

                codeper.clear()
            else:
                result = maxv + " Not found" + "% (" + newWord + ")"
                    
                print(result)
                moreinfo += ("More info: " ": Not found" +"\n")
                foundings += (result + " ")
                foundforgard += (str(maxv) + " ")

                codeper.clear()

        if not foundcheck:
            ogsen.remove(ogsen[0])

        temp = ogsen.copy()    
        #returns the stats for found words.
        #print(foundings)

    eng = ""

    for i in foundforgard.split("} "):
        n = i+ "}"
        
        if n != "}":
            c = dictionaryFull.get(n,"Not found.")

            


            if isinstance(c,list):
                #eng += c[0][c[0].index("["):c[0].index("]")]
                for i in c:
                    if "not found" not in i.lower():
                        if ")" and "(" in i.lower():
                            b = i.index("(")
                            e= i.index(")")
                            tr = i[b:e+1]
                            i = i.replace(tr,"")
                            xczxca= i[i.index("[")+1:i.index("]")].strip().lower()
                        if i[i.index("[")+1:i.index("]")].strip().lower() in sen:
                            tt = (i[i.index("]")+1:])
                            eng += tt +" "
                            break
                
            if isinstance(c, str):
                if ")" and "(" in c.lower():
                            b = c.index("(")
                            e= c.index(")")
                            tr = c[b:e+1]
                            c = c.replace(tr,"")
                if "not found" not in c.lower():
                    #eng += c[c.index("["):c.index("]")]
                    tt = (c[c.index("]")+1:])
                    eng += tt +" "


    
    res = foundforgard.replace("{", "")
    hiero = gardinersMultiDirect(res)
    #res = res.replace("}", " ")
    print("\n" + moreinfo)
    print(foundforgard)
    print(eng)
    print(hiero)

    return moreinfo, foundforgard, eng, hiero
    
def newSearchForGard(sen,dictionaryFull):

    newsen = ""
    for i in sen.split(" "):
        
        #value = {v for v in gardinersCodetoSymbolsf if gardinersCodetoSymbolsf[v]==i}
        if i in gardinersCodetoSymbolsf.values():
            if i != "":
                value = list(gardinersCodetoSymbolsf.keys())[list(gardinersCodetoSymbolsf.values()).index(i)]
                newsen += value + " "
        else:
            if i != "":
                newsen += "{-}"

    sen = newsen



    temp = []
    newWord = ""

    codeper = {}
    foundings = ""
    foundforgard = ""
    moreinfo = ""

    ogsen = []

    foundcheck = False

    if len(sen) != 0:
        if sen.lower()[-1] == " ":
            sen = sen[:-1]

    for word in sen.lower().split(" "):

        ogsen.append(word)

    for word in sen.lower().split(" "):

        temp.append(word)
    
    while len(ogsen) != 0:
        
        foundcheck = False

        while len(temp) != 0:
            newWord = ""
            for i in range(len(temp)):
                if len(temp) > 1:
                    newWord += temp[i] + " "
                elif len(temp) == 1:
                    newWord += temp[i]
                else: newWord += temp[i]
            
            if len(newWord) != 0:
                if newWord[-1] == " ":
                    newWord = newWord[:-1]

            #if found --------

            for code, trans in dictionaryFull.items():

                #if it matches we add it to a temp dictionary
                codew = code.replace("{","")
                codew = codew.replace("}","")

                if newWord == codew.lower().strip():
                    #per = (len(newWord)/len(codew.lower().strip())*100) + 10
                    per = similar(newWord,codew.lower().strip())*100
                    if per > 80:
                        #print("sure match (", per, ")", code)
                        codeper[code] = per
                        foundcheck = True

                elif newWord in codew.lower().strip():
                    #per = (len(newWord)/len(codew.lower().strip())*100) + 5
                    per = similar(newWord,codew.lower().strip())*100
                    if per > 80:
                        #print("not accurate (", per, ")", code)
                        codeper[code] = per
                        foundcheck = True
                else:
                    per = 0
                    codeper["{-}"] = per
                
            if foundcheck:
                for i in newWord.split(" "):
                    if len(temp) != 0:
                        temp.remove(i)
                    if len(ogsen) != 0:
                        ogsen.remove(i)
            else:
                temp.pop()
                        

            #if the temp dictionary isnt empty, it finds the max of the dictionary (the one with the best accuracy)
            # and returns it and adds it formatted to get translated into symbols using the Gardiner function.

            

        if len(codeper) != 0:
            #print(codeper)
            #print(len(codeper))
            maxv = max(codeper, key=codeper.get)
            if maxv != "{-}":

                result = maxv + " " +  str(codeper[maxv]) + "% (" + newWord + ")"
                    
                print(result + "Line 1609")
                moreinfo += ("More info: (" + str(codeper[maxv]) + "%) " + str(maxv) + ": " + str(dictionaryFull[maxv]) +"\n")
                foundings += (result + " ")
                foundforgard += (str(maxv) + " ")

                codeper.clear()
            else:
                result = maxv + " Not found" + "% (" + newWord + ")"
                    
                print(result + "Line 1618")
                moreinfo += ("More info: {" + newWord + "} Not found" +"\n")
                foundings += (result + " ")
                foundforgard += (str(maxv) + " ")

                codeper.clear()

        if not foundcheck:
            ogsen.remove(ogsen[0])

        temp = ogsen.copy()    
        #returns the stats for found words.
        #print(foundings)

    transl = ""

    for i in foundforgard.split("} "):
        n = i+ "}"
        
        if n != "}":
            c = dictionaryFull.get(n,"Not found.")

            


            if isinstance(c,list):
                #transl += c[0][c[0].index("["):c[0].index("]")]
                for i in c:
                    if "not found" not in i.lower():
                        if ")" and "(" in i.lower():
                            b = i.index("(")
                            e= i.index(")")
                            tr = i[b:e+1]
                            i = i.replace(tr,"")
                        if "not found" not in i.lower():
                            tt = (i[i.index("["):i.index("]")+1])
                            transl += tt +" "
                            break
                
            if isinstance(c, str):
                if ")" and "(" in c.lower():
                            b = c.index("(")
                            e= c.index(")")
                            tr = c[b:e+1]
                            c = c.replace(tr,"")
                if "not found" not in c.lower():
                    #transl += c[c.index("["):c.index("]")]
                    tt = (c[c.index("["):c.index("]")+1])
                    transl += tt+ " "


    allpossiblesen = []
    tt = []
    nffg = foundforgard.replace("} {","}.{")
    nffg = nffg[:-1]
    for words in nffg.split("."):
        
        if words != "{-}" :
            if words!= "":
                print(words + "Line 1677")
                curr = dictionaryFull[words]

                if isinstance(curr, list):
                    tt = []
                    for i in curr:
                        
                        if "]" in i and "[" in i:
                            bs = i.index("]")
                            es = i.index("[")
                            t = i[es:bs+1]
                            i = i.replace(t,"")
                            
                        if ")" in i and "(" in i:
                            bb = i.index(")")
                            eb = i.index("(")
                            t = i[eb:bb+1]
                            i = i.replace(t,"")
                            

                        tt.append(i)
                    allpossiblesen.append(tt)

                if isinstance(curr, str):
                    tt = []

                    if "]" in curr:
                        bs = curr.index("]")
                        curr = curr[bs+1:]
                        #curr = curr.replace(" ", "")
                    if ")" in curr and "(" in curr:
                        bb = curr.index("(")
                        be = curr.index(")")
                        test = curr[bb:be+1]
                        curr = curr.replace(curr[bb:be+1],"")
                        #curr = curr.replace(" ", "")

                    tt.append(curr)
                    allpossiblesen.append(tt)


        moreresults = ""
        if len(allpossiblesen) <= 5:

            bbbb = (list(itertools.product(*allpossiblesen)))
            tsa = ""
            listtsa = []
            sentoprint = ""
            #print(allpossiblesen)
            for l in bbbb:
                for b in l:
                    tsa += b + " "
                tsa += "\n"

            for line in tsa.split("\n"):
                if line != "":
                    listtsa.append(line)
            
            if len(listtsa) != 0:
                sentoprint = (listtsa[0])

            for count,l in enumerate(listtsa):
                moreresults += str(count) + ")> "+ l + "\n"


    """
    print(tsa)
    tool = language_tool_python.LanguageTool('en-US')

    finlist = []

    for i in listtsa:
        matches = tool.check(i)
        if len(matches) == 0:
            print(i)
            finlist.append(i)
            print(len(matches))
    
    for i in finlist:
        corrected_text = GingerIt().parse(i)
        print(corrected_text) """
    
    finalsen = ""
    for i in allpossiblesen:
        if len(i) >0:
            blankspace = "  "
            tt = ""
            for blankspace in i[0]:
                tt= i[0].replace("   "," ")
            finalsen += tt + " "



    
    res = foundforgard.replace("{", "")
    hiero = gardinersMultiDirect(res)
    #res = res.replace("}", " ")
    print("\n" + moreinfo)
    print(finalsen)
    
    print(foundforgard)
    #print(sentoprint)
    print(transl)
    print(hiero)
    return moreinfo,foundforgard,transl,hiero,finalsen,moreresults

    #calls function to translate to symbols using gardiners code.

def newSearchForHiero(sen,dictionaryFull):


    newsen = ""
    for i in sen.split(" "):
        #value = {v for v in gardinersCodetoSymbolsf if gardinersCodetoSymbolsf[v]==i}
        if i in gardinersCodetoSymbolsf.values():
            if i != "":
                value = list(gardinersCodetoSymbolsf.keys())[list(gardinersCodetoSymbolsf.values()).index(i)]
                newsen += value + " "
        else:
            if i != "":
                newsen += "{-}"

    sen = newsen



    temp = []
    newWord = ""

    codeper = {}
    foundings = ""
    foundforgard = ""
    moreinfo = ""

    ogsen = []

    foundcheck = False

    if sen.lower()[-1] == " ":
        sen = sen[:-1]

    for word in sen.lower().split(" "):
        ogsen.append(word)

    for word in sen.lower().split(" "):
        temp.append(word)
    
    while len(ogsen) != 0:
        
        foundcheck = False

        while len(temp) != 0:
            newWord = ""
            for i in range(len(temp)):
                if len(temp) > 1:
                    newWord += temp[i] + " "
                elif len(temp) == 1:
                    newWord += temp[i]
                else: newWord += temp[i]
            
            if len(newWord) != 0:
                if newWord[-1] == " ":
                    newWord = newWord[:-1]

            #if found --------

            for code, trans in dictionaryFull.items():

                #if it matches we add it to a temp dictionary
                codew = code.replace("{","")
                codew = codew.replace("}","")

                if newWord == codew.lower().strip():
                    #per = (len(newWord)/len(codew.lower().strip())*100) + 10
                    per = similar(newWord,codew.lower().strip())*100
                    if per > 80:
                        #print("sure match (", per, ")", code)
                        codeper[code] = per
                        foundcheck = True

                elif newWord in codew.lower().strip():
                    #per = (len(newWord)/len(codew.lower().strip())*100) + 5
                    per = similar(newWord,codew.lower().strip())*100
                    if per > 80:
                        #print("not accurate (", per, ")", code)
                        codeper[code] = per
                        foundcheck = True
                else:
                    per = 0
                    codeper["{-}"] = per
                
            if foundcheck:
                for i in newWord.split(" "):
                    if len(temp) != 0:
                        temp.remove(i)
                    if len(ogsen) != 0:
                        ogsen.remove(i)
            else:
                temp.pop()
                        

            #if the temp dictionary isnt empty, it finds the max of the dictionary (the one with the best accuracy)
            # and returns it and adds it formatted to get translated into symbols using the Gardiner function.

            

        if len(codeper) != 0:
            #print(codeper)
            #print(len(codeper))
            maxv = max(codeper, key=codeper.get)
            if maxv != "{-}":

                result = maxv + " " +  str(codeper[maxv]) + "% (" + newWord + ")"
                    
                print(result)
                moreinfo += ("More info: (" + str(codeper[maxv]) + "%) " + str(maxv) + ": " + str(dictionaryFull[maxv]) +"\n")
                foundings += (result + " ")
                foundforgard += (str(maxv) + " ")

                codeper.clear()
            else:
                result = maxv + " Not found" + "% (" + newWord + ")"
                    
                print(result)
                moreinfo += ("More info: {" + newWord + "} Not found" +"\n")
                foundings += (result + " ")
                foundforgard += (str(maxv) + " ")

                codeper.clear()

        if not foundcheck:
            ogsen.remove(ogsen[0])

        temp = ogsen.copy()    
        #returns the stats for found words.
        #print(foundings)

    transl = ""

    for i in foundforgard.split("} "):
        n = i+ "}"
        
        if n != "}":
            c = dictionaryFull.get(n,"Not found.")

            


            if isinstance(c,list):
                #transl += c[0][c[0].index("["):c[0].index("]")]
                for i in c:
                    if "not found" not in i.lower():
                        if ")" and "(" in i.lower():
                            b = i.index("(")
                            e= i.index(")")
                            tr = i[b:e+1]
                            i = i.replace(tr,"")
                        if "not found" not in i.lower():
                            tt = (i[i.index("["):i.index("]")+1])
                            transl += tt +" "
                            break
                
            if isinstance(c, str):
                if ")" and "(" in c.lower():
                            b = c.index("(")
                            e= c.index(")")
                            tr = c[b:e+1]
                            c = c.replace(tr,"")
                if "not found" not in c.lower():
                    #transl += c[c.index("["):c.index("]")]
                    tt = (c[c.index("["):c.index("]")+1])
                    transl += tt+ " "


    allpossiblesen = []
    tt = []
    nffg = foundforgard.replace("} {","}.{")
    nffg = nffg[:-1]
    for words in nffg.split("."):
        
        if words != "{-}":
            curr = dictionaryFull[words]

            if isinstance(curr, list):
                tt = []
                for i in curr:
                    
                    if "]" in i and "[" in i:
                        bs = i.index("]")
                        es = i.index("[")
                        t = i[es:bs+1]
                        i = i.replace(t,"")
                        
                    if ")" in i and "(" in i:
                        bb = i.index(")")
                        eb = i.index("(")
                        t = i[eb:bb+1]
                        i = i.replace(t,"")
                        

                    tt.append(i)
                allpossiblesen.append(tt)

            if isinstance(curr, str):
                tt = []

                if "]" in curr:
                    bs = curr.index("]")
                    curr = curr[bs+1:]
                    #curr = curr.replace(" ", "")
                if ")" in curr and "(" in curr:
                    bb = curr.index("(")
                    be = curr.index(")")
                    test = curr[bb:be+1]
                    curr = curr.replace(curr[bb:be+1],"")
                    #curr = curr.replace(" ", "")

                tt.append(curr)
                allpossiblesen.append(tt)


    moreresults = ""
    if len(allpossiblesen) <= 5:

        bbbb = (list(itertools.product(*allpossiblesen)))
        tsa = ""
        listtsa = []
        sentoprint = ""
        #print(allpossiblesen)
        for l in bbbb:
            for b in l:
                tsa += b + " "
            tsa += "\n"

        for line in tsa.split("\n"):
            if line != "":
                listtsa.append(line)
        
        if len(listtsa) != 0:
            sentoprint = (listtsa[0])

        for count,l in enumerate(listtsa):
            moreresults += str(count) + ")> "+ l + "\n"


    """
    print(tsa)
    tool = language_tool_python.LanguageTool('en-US')

    finlist = []

    for i in listtsa:
        matches = tool.check(i)
        if len(matches) == 0:
            print(i)
            finlist.append(i)
            print(len(matches))
    
    for i in finlist:
        corrected_text = GingerIt().parse(i)
        print(corrected_text) """
    
    finalsen = ""
    for i in allpossiblesen:
        if len(i) >0:
            blankspace = "  "
            tt = ""
            for blankspace in i[0]:
                tt= i[0].replace("   "," ")
            finalsen += tt + " "



    
    res = foundforgard.replace("{", "")
    hiero = gardinersMultiDirect(res)
    #res = res.replace("}", " ")
    print("\n" + moreinfo)
    print(finalsen)
    
    print(foundforgard)
    #print(sentoprint)
    print(transl)
    print(hiero)
    return moreinfo,foundforgard,transl,hiero,finalsen,moreresults

    #calls function to translate to symbols using gardiners code.

def formater():

    #Formats by making elements of every single category of the gardiners codes.

    a,b,c,d,e,f,g,h,i,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,aa = {},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}
    

    for gard, sign in gardinersCodetoSymbolsf.items():
        
        if gard[0] == "A" and gard[1] != "a":
            a[gard] = sign
        if gard[0] == "B":
            b[gard] = sign
        if gard[0] == "C":
            c[gard] = sign
        if gard[0] == "D":
            d[gard] = sign
        if gard[0] == "E":
            e[gard] = sign
        if gard[0] == "F":
            f[gard] = sign
        if gard[0] == "G":
            g[gard] = sign
        if gard[0] == "H":
            h[gard] = sign
        if gard[0] == "I":
            i[gard] = sign
        if gard[0] == "K":
            k[gard] = sign
        if gard[0] == "L":
            l[gard] = sign
        if gard[0] == "M":
            m[gard] = sign
        if gard[0] == "N":
            n[gard] = sign
        if gard[0] == "O":
            o[gard] = sign
        if gard[0] == "P":
            p[gard] = sign
        if gard[0] == "Q":
            q[gard] = sign
        if gard[0] == "R":
            r[gard] = sign
        if gard[0] == "S":
            s[gard] = sign
        if gard[0] == "T":
            t[gard] = sign
        if gard[0] == "U":
            u[gard] = sign
        if gard[0] == "V":
            v[gard] = sign
        if gard[0] == "W":
            w[gard] = sign
        if gard[0] == "X":
            x[gard] = sign
        if gard[0] == "Y":
            y[gard] = sign
        if gard[0] == "Z":
            z[gard] = sign
        if gard[0] == "A" and gard[1] == "a":
            aa[gard] = sign 

    return a,b,c,d,e,f,g,h,i,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,aa
    
def useDir(dir):

    #Takes a directory and returns the dictionary after using literal eval on it.

    st = ""
    with open(dir) as f:
        text = f.readlines()
    for i in text:
        st += i
    
    tdict = ast.literal_eval(st)

    return tdict

def saveLog(text):

    #Saves the log using the date and time, and it takes a text as the only arguement.

    time = QtCore.QTime.currentTime().toString("h:mm:ss AP")
    date = QtCore.QDate.currentDate().toString('dd/MM/yyyy')

    st = "[" + date + " " + time + "] " + text + "\n"

    with open("Log.txt","a+",encoding='utf-8') as file:
        file.write(st)




dictionaryForNamesEn = """{
    'a':'ð“„¿',
    'b':'ð“ƒ€',
    'c':'ð“Ž¡',
    'd':'ð“‚§',
    'e':'ð“‚',
    'f':'ð“†‘',
    'g':'ð“Ž¼',
    'h':'ð“‰”',
    'i':'ð“‡‹',
    'j':'ð“†“',
    'k':'ð“Ž¡',
    'l':'ð“ƒ­',
    'm':'ð“…“',
    'n':'ð“ˆ–',
    'o':'ð“¯',
    'p':'ð“Šª',
    'q':'ð“˜',
    'r':'ð“‚‹',
    's':'ð“‹´',
    't':'ð“',
    'u':'ð“…±',
    'v':'ð“†‘',
    'w':'ð“…±',
    'x':'ð“„¡',
    'y':'ð“‡Œ',
    'z':'ð“Šƒ'
}"""

dictionaryForNamesAr = """{
    'Ø§':'ð“„¿',
    'Ø¨':'ð“ƒ€',
    'Øª':'ð“',
    'Ø«':'ð“¿',
    'Ø¬':'ð“Ž¼',
    'Ø­':'ð“Ž›',
    'Ø®':'ð“',
    'Ø¯':'ð“‚§',
    'Ø°':'ð“¿',
    'Ø±':'ð“‚‹',
    'Ø²':'ð“Šƒ',
    'Ø³':'ð“‹´',
    'Ø´':'ð“ˆ™',
    'Øµ':'ð“‹´',
    'Ø¶':'ð“‚§',
    'Ø·':'ð“',
    'Ø¸':'ð“Šƒ',
    'Ø¹':'ð“‚',
    'Øº':'ð“„¡',
    'Ù':'ð“†‘',
    'Ù‚':'ð“˜',
    'Ùƒ':'ð“Ž¡',
    'Ù„':'ð“ƒ­',
    'Ù…':'ð“…“',
    'Ù†':'ð“ˆ–',
    'Ù‡':'ð“‰”',
    'Ùˆ':'ð“…±',
    'ÙŠ':'ð“‡Œ'
}"""


dictionaryForNamesEn = ast.literal_eval(dictionaryForNamesEn)
dictionaryForNamesAr = ast.literal_eval(dictionaryForNamesAr)

def namefinder(uinp, dictionaryfornames):

    newword = ""

    for i in uinp:
        if i in dictionaryfornames.keys():
            newword+=dictionaryfornames[i] + " "

            
    print(newword)
    return newword
    
""" mainDictionary = ast.literal_eval (dictionaryMaker.defaultDictionary)

uinp = input("Enter name: ")
newSearchForGard(uinp,mainDictionary) """